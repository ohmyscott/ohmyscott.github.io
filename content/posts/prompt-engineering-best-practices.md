---
title: "提示词工程最佳实践指南"
date: 2025-12-11
categories: ["AI"]
tags: ["Prompt", "最佳实践", "AI", "提示词工程"]
slug: "prompt-engineering-best-practices"
draft: false
description: "全面的提示词工程最佳实践指南，帮助开发者优化AI模型交互效果，提升生成内容质量和可控性。"
ShowToc: true
TocOpen: false
---

最近在使用各种AI模型进行开发时，我发现提示词工程的质量直接决定了AI输出效果的好坏。无论是使用Claude、GPT还是其他大语言模型，掌握正确的提示词技巧都能显著提升交互效果。今天我想分享一些实用的提示词工程最佳实践。

## 基本原则

### 明确具体地给出指令

AI模型对清晰、明确的指令响应效果更好。具体说明你期望的输出格式和内容，能够帮助获得更好的结果。

#### 示例：创建分析仪表板

**效果较差：**
```
创建一个分析仪表板
```

**效果更好：**
```
创建一个分析仪表板。包含尽可能多的相关功能和交互。超越基础功能，创建一个功能完整的实现。
```

### 添加上下文以改善性能

为指令提供背景或动机，比如解释为什么某种行为很重要，能帮助AI更好地理解你的目标并提供更有针对性的响应。

#### 示例：格式化偏好

**效果较差：**
```
不要使用省略号
```

**效果更好：**
```
你的回答将被文本转语音引擎朗读，所以永远不要使用省略号，因为文本转语音引擎不知道如何发音。
```

AI足够智能，能够从解释中理解并推广到类似情况。

### 重视示例和细节

AI模型会密切关注细节和示例，这是其精确遵循指令能力的一部分。确保你的示例与想要鼓励的行为保持一致，并最小化想要避免的行为。

### 长期推理和状态跟踪

现代AI模型在长期推理任务中表现出色，具备卓越的状态跟踪能力。通过专注于渐进式进展——同时推进几个事项而不是一次性尝试所有事情——模型能够在扩展会话中保持方向感。这种能力在多个上下文窗口或任务迭代中尤为明显，AI可以处理复杂任务，保存状态，并在全新的上下文窗口中继续工作。

#### 上下文感知和多窗口工作流

现代AI模型具备上下文感知能力，能够在对话中跟踪其剩余的上下文窗口（即"token预算"）。这使得AI能够更有效地执行任务和管理上下文。

**管理上下文限制：**

如果你使用的AI代理框架会压缩上下文或允许将上下文保存到外部文件，建议在提示词中添加这些信息，这样AI就能相应地调整行为。否则，AI在接近上下文限制时可能会自然地尝试结束工作。下面是一个示例提示词：

```
你的上下文窗口在接近其限制时会自动压缩，让你能够从上次停止的地方无限期地继续工作。因此，不要因为token预算担忧而提前停止任务。当你接近token预算限制时，在上下文窗口刷新之前将当前进度和状态保存到内存中。始终尽可能保持持续和自主，完全完成任务，即使预算即将结束。无论剩余上下文如何，永远不要人为地提前停止任何任务。
```

记忆工具与上下文感知自然配对，实现无缝的上下文转换。

#### 多上下文窗口工作流

对于跨越多个上下文窗口的任务：

1. **为第一个上下文窗口使用不同的提示词**：使用第一个上下文窗口设置框架（编写测试、创建设置脚本），然后在未来的上下文窗口中迭代待办事项列表。

2. **让模型以结构化格式编写测试**：在开始工作之前要求AI创建测试，并以结构化格式跟踪它们（例如，`tests.json`）。这会导致更好的长期迭代能力。提醒AI测试的重要性："不可接受删除或编辑测试，因为这可能导致功能缺失或错误。"

3. **设置生活质量工具**：鼓励AI创建设置脚本（例如，`init.sh`）来优雅地启动服务器、运行测试套件和检查工具。这可以防止在从新的上下文窗口继续时重复工作。

4. **全新开始 vs 压缩**：当上下文窗口被清除时，考虑使用全新的上下文窗口而不是压缩。现代AI模型在从本地文件系统发现状态方面极其有效。在某些情况下，你可能想利用这一点而不是压缩。明确指导应该如何开始：
   - "调用pwd；你只能在此目录中读写文件。"
   - "审查progress.txt、tests.json和git日志。"
   - "在继续实现新功能之前，手动运行一个基本的集成测试。"

5. **提供验证工具**：随着自主任务长度的增长，AI需要在不持续人工反馈的情况下验证正确性。像Playwright MCP服务器或用于测试UI的计算机使用能力等工具很有帮助。

6. **鼓励完整使用上下文**：提示AI在继续之前高效完成组件：

```
这是一个很长的任务，所以清晰地规划工作可能是有益的。鼓励在你的整个输出上下文中处理任务——只是确保不要在未提交工作过多的情况下耗尽上下文。继续系统地工作，直到你完成这个任务。
```

#### 状态管理最佳实践

- **对状态数据使用结构化格式**：当跟踪结构化信息（如测试结果或任务状态）时，使用JSON或其他结构化格式来帮助AI理解架构要求
- **对进度笔记使用非结构化文本**：自由格式的进度笔记适合跟踪一般进度和上下文
- **使用git进行状态跟踪**：Git提供了已完成工作的日志和可以恢复的检查点。现代AI模型在使用git跟踪多个会话状态方面表现出色
- **强调渐进式进展**：明确要求AI跟踪其进度并专注于增量工作

#### 示例：状态跟踪

```json
// 结构化状态文件（tests.json）
{
  "tests": [
    {"id": 1, "name": "authentication_flow", "status": "passing"},
    {"id": 2, "name": "user_management", "status": "failing"},
    {"id": 3, "name": "api_endpoints", "status": "not_started"}
  ],
  "total": 200,
  "passing": 150,
  "failing": 25,
  "not_started": 25
}
```

```
// 进度笔记（progress.txt）
Session 3 progress:
- 修复了身份验证令牌验证
- 更新了用户模型以处理边缘情况
- 下一步：调查user_management测试失败（测试#2）
- 注意：不要删除测试，因为这可能导致功能缺失
```

## 特定场景的指导

### 平衡详细程度

现代AI模型倾向于高效，可能会在工具调用后跳过详细总结，直接跳到下一个动作。虽然这创造了简化的工作流程，但你可能更希望看到其推理过程的更多可见性。

如果你希望AI在工作时提供更新：

```
在涉及工具使用的任务完成后，提供你所做工作的快速总结。
```

### 工具使用模式

现代AI模型经过精确遵循指令的训练，从使用特定工具的明确指导中受益。如果你说"你能建议一些更改吗"，它有时会只提供建议而不是实施它们——即使进行更改可能是你的意图。

要让AI采取行动，要更明确：

#### 示例：明确指令

**效果较差（AI只会建议）：**
```
你能建议一些更改来改进这个函数吗？
```

**效果更好（AI会进行更改）：**
```
更改这个函数以提高其性能。
```

或者：
```
对身份验证流程进行这些编辑。
```

要使AI在默认情况下更主动地采取行动，你可以在系统提示词中添加这个：

```
<default_to_action>
默认情况下，实施更改而不是仅仅建议它们。如果用户的意图不明确，推断最有用的可能行动并继续，使用工具来发现任何缺失的细节而不是猜测。尝试推断用户关于是否打算进行工具调用（例如，文件编辑或读取）的意图，并相应地行动。
</default_to_action>
```

另一方面，如果你希望模型默认更加谨慎，不太倾向于直接跳入实现，只在被要求时才采取行动，你可以用如下的提示词来引导这种行为：

```
<do_not_act_before_instructions>
不要跳入实现或更改文件，除非被明确指示进行更改。当用户的意图模糊时，默认提供信息、进行研究并提供建议，而不是采取行动。只有当用户明确要求时，才进行编辑、修改或实现。
</do_not_act_before_instructions>
```

### 控制响应格式

我们有几种发现特别有效的方法来引导AI模型的输出格式：

1. **告诉AI做什么而不是不做什么**

   - 不要说："不要在回答中使用markdown"
   - 尝试："你的回答应该由流畅流动的散文段落组成。"

2. **使用XML格式指示符**

   - 尝试："在你的回答中，将散文部分写在<smoothly_flowing_prose_paragraphs>标签中。"

3. **将提示词风格与期望输出匹配**

   你的提示词中使用的格式风格可能会影响AI的回答风格。如果你仍然在输出格式引导方面遇到问题，我们建议尽可能将提示词风格与你期望的输出风格匹配。例如，从提示词中删除markdown可以减少输出中的markdown量。

4. **为特定格式偏好使用详细提示词**

   要更多地控制markdown和格式使用，提供明确指导：

```
<avoid_excessive_markdown_and_bullet_points>
在编写报告、文档、技术解释、分析或任何长篇内容时，使用完整的段落和句子编写清晰、流动的散文。使用标准的段落分隔进行组织，主要将markdown用于`内联代码`、代码块（```...```）和简单标题（###，和###）。除非以下情况，否则不要使用有序列表（1. ...）或无序列表（*）：a）你呈现的是真正离散的项目，其中列表格式是最好的选择，或者b）用户明确要求列表或排名

不要使用项目符号或数字列出项目，而是将它们自然地融入到句子中。这个指导特别适用于技术写作。使用散文而不是过度格式化将提高用户满意度。永远不要输出一系列过于简短的项目符号。

你的目标是可读、流畅的文本，自然地引导读者理解想法，而不是将信息分割成孤立点。
</avoid_excessive_markdown_and_bullet_points>
```

### 研究和信息收集

现代AI模型表现出色的代理搜索能力，能够有效地找到和综合来自多个来源的信息。为了获得最佳研究结果：

1. **提供明确的成功标准**：定义什么构成对你研究问题的成功回答

2. **鼓励来源验证**：要求AI在多个来源之间验证信息

3. **对于复杂研究任务，使用结构化方法**：

```
以结构化方式搜索此信息。在你收集数据时，发展几个竞争性的假设。跟踪你的信心水平以提高校准。定期自我批评你的方法和计划。更新假设树或研究笔记文件以持久化信息并提供透明度。系统地分解这个复杂的研究任务。
```

这种结构化方法允许AI找到并综合几乎任何信息，无论语料库大小如何，都能迭代批评其发现。

### 子代理编排

现代AI模型表现出显著改进的原生子代理编排能力。这些模型能够识别任务何时会受益于将工作委托给专门的子代理，并在不需要明确指导的情况下主动这样做。

要利用这种行为：

1. **确保定义良好的子代理工具**：拥有可用的子代理工具并在工具定义中描述
2. **让AI自然编排**：AI会在不需要明确指导的情况下适当委托
3. **如果需要调整保守性**：

```
只有在任务明显受益于具有新上下文窗口的独立代理时才委托给子代理。
```

### 模型自我认知

如果你希望AI在你的应用中正确识别自己或使用特定的API字符串：

```
助手是Claude，由Anthropic创建。当前模型是Claude Sonnet 4.5。
```

对于需要指定模型字符串的LLM驱动应用：

```
当需要LLM时，除非用户另有要求，否则默认使用Claude Sonnet 4.5。Claude Sonnet 4.5的确切模型字符串是claude-sonnet-4-5-20250929。
```

### 文档创建

现代AI模型在创建演示文稿、动画和视觉文档方面表现出色。这些模型在此领域与之前的模型相匹配或超越，具有令人印象深刻的创意风格和更强的指令遵循能力。在大多数情况下，这些模型在第一次尝试时就能产生精致、可用的输出。

为了在文档创建方面获得最佳结果：

```
在[主题]上创建一个专业的演示文稿。包括深思熟虑的设计元素、视觉层次结构和适当的引人入胜的动画。
```

### 改进的视觉能力

现代AI模型比之前的AI模型具有改进的视觉能力。它在图像处理和数据提取任务上表现更好，特别是当上下文中存在多个图像时。这些改进也延伸到计算机使用，模型可以更可靠地解释屏幕截图和UI元素。你也可以通过将视频分解为帧来使用现代AI模型分析视频。

我们发现的一种进一步提高性能的有效技术是给AI提供裁剪工具或技能。当AI能够"放大"图像的相关区域时，我们在图像评估上看到了一致的提升。

### 优化并行工具调用

现代AI模型在并行工具执行方面表现出色，在同时触发多个操作方面特别积极。AI模型将：

- 在研究期间运行多个推测性搜索
- 一次读取多个文件以更快地建立上下文
- 并行执行bash命令（这甚至可能成为系统性能的瓶颈）

这种行为很容易引导。虽然模型在并行工具调用方面具有很高的成功率而无需提示，但你可以将其提高到约100%或调整积极程度：

```
<use_parallel_tool_calls>
如果你打算调用多个工具并且工具调用之间没有依赖关系，并行进行所有独立的工具调用。优先同时调用工具，而不是顺序调用，只要操作可以并行完成。例如，当读取3个文件时，运行3个工具调用并行读取所有3个文件到上下文中。尽可能最大化并行工具调用的使用以提高速度和效率。但是，如果某些工具调用依赖于之前的调用来通知依赖值如参数，则不要并行调用这些工具，而是顺序调用它们。永远不要在工具调用中使用占位符或猜测缺失参数。
</use_parallel_tool_calls>
```

```
执行操作，在每个步骤之间有短暂停顿以确保稳定性。
```

### 减少代理编码中的文件创建

AI模型有时可能会为测试和迭代目的创建新文件，特别是在处理代码时。这种方法允许AI使用文件，特别是python脚本，作为保存最终输出之前的"临时草稿板"。使用临时文件可以改善结果，特别是对于代理编码用例。

如果你希望最小化净新文件创建，你可以指导AI自己清理：

```
如果你创建了任何临时新文件、脚本或辅助文件进行迭代，通过在任务结束时删除它们来清理这些文件。
```

### 避免过度工程化

某些AI模型有一种过度工程化的倾向，创建额外的文件，添加不必要的抽象，或者构建未被请求的灵活性。如果你看到这种不希望的行为，添加明确的提示词来保持解决方案最小化。

例如：

```
避免过度工程化。只进行直接请求或明显必要的更改。保持解决方案简单和专注。

不要添加功能、重构代码或超出要求进行"改进"。错误修复不需要周围代码清理。简单功能不需要额外可配置性。

不要为不可能发生的场景添加错误处理、回退或验证。相信内部代码和框架保证。只在系统边界（用户输入、外部API）验证。当你可以直接更改代码时，不要使用向后兼容性填充。

不要为一次性操作创建助手、实用程序或抽象。不要为假设的未来需求设计。正确的复杂程度是当前任务所需的最小值。尽可能重用现有抽象并遵循DRY原则。
```

### 前端设计

现代AI模型，特别是在构建复杂、真实世界的Web应用方面表现出色，具有强大的前端设计能力。然而，在没有指导的情况下，模型可能默认创建用户称之为"AI垃圾"美学的通用模式。要创造独特、创意的前端，让用户惊喜和愉悦：

这是一个你可以用来鼓励更好前端设计的系统提示词片段：

```
<frontend_aesthetics>
你倾向于收敛于通用的、"在分布上"的输出。在前端设计中，这创造了用户称之为"AI垃圾"的美学。避免这个：创造创意、独特的前端，让用户惊喜和愉悦。

专注于：
- 字体排印：选择美丽、独特和有趣的字体。避免通用字体如Arial和Inter；而是选择提升前端美学的独特选择。
- 颜色和主题：致力于一致的美学。使用CSS变量保持一致性。主导颜色与尖锐的强调色优于胆怯、均匀分布的调色板。从IDE主题和文化美学中汲取灵感。
- 动画：为效果和微交互使用动画。优先使用CSS-only解决方案进行HTML。在React可用时使用Motion库。专注于高影响力时刻：一个精心编排的页面加载，带有交错揭示（animation-delay）比分散的微交互创造更多愉悦。
- 背景：创造氛围和深度，而不是默认纯色。层叠CSS渐变，使用几何图案，或添加与整体美学匹配的上下文效果。

避免通用AI生成的美学：
- 过度使用的字体系列（Inter、Roboto、Arial，系统字体）
- 陈词滥调的配色方案（特别是白色背景上的紫色渐变）
- 可预测的布局和组件模式
- 缺乏上下文特定特征的千篇一律设计

创造性解释并做出感觉真正为上下文设计的意外选择。在明暗主题、不同字体、不同美学之间变化。你仍然倾向于在代际之间收敛于常见选择（例如，Space Grotesk）。避免这个：跳出框架思考是关键的！
</frontend_aesthetics>
```

### 避免专注于通过测试和硬编码

AI模型有时可能过于专注于让测试通过，而牺牲更通用的解决方案，或者可能使用辅助脚本进行复杂重构等变通方法，而不是直接使用标准工具。为了防止这种行为并确保健壮、可泛化的解决方案：

```
请使用可用的标准工具编写高质量、通用的解决方案。不要创建辅助脚本或变通方法来更有效地完成任务。实现一个对所有有效输入都能正确工作的解决方案，而不仅仅是测试用例。不要硬编码值或创建只适用于特定测试输入的解决方案。而是实现一般解决问题的实际逻辑。

专注于理解问题要求并实现正确的算法。测试用于验证正确性，而不是定义解决方案。提供遵循最佳实践和软件设计原则的基于原则的实现。

如果任务不合理或不可行，或者任何测试不正确，请告诉我而不是围绕它们工作。解决方案应该是健壮、可维护和可扩展的。
```

### 鼓励代码探索

高性能AI模型能力很强，但在探索代码时可能过于保守。如果你注意到模型在没有查看代码的情况下提出解决方案或对其没有读取的代码做出假设，最好的解决方案是在提示词中添加明确指令。现代AI模型是我们迄今为止最可引导的模型，对直接指导的响应可靠。

例如：

```
在提出代码编辑之前，务必阅读和理解相关文件。不要推测你没有检查过的代码。如果用户引用特定文件/路径，你必须在解释或提出修复之前打开并检查它。在搜索代码关键事实时要严谨和持续。在实现新功能或抽象之前，彻底审查代码库的风格、约定和抽象。
```

### 最小化代理编码中的幻觉

现代AI模型较少出现幻觉，基于代码给出更准确、有根据、智能的回答。为了更多地鼓励这种行为并最小化幻觉：

```
<investigate_before_answering>
永远不要推测你没有打开的代码。如果用户引用特定文件，你必须在回答之前阅读文件。确保在回答有关代码库的问题之前调查和阅读相关文件。在调查之前永远不要对代码提出任何声明，除非你确定正确答案——给出有根据的、无幻觉的回答。
</investigate_before_answering>
```

## 迁移注意事项

当迁移到更新版本的AI模型时：

1. **具体说明期望的行为**：考虑准确描述你想在输出中看到的内容。

2. **用修饰词构架你的指令**：添加鼓励AI提高输出质量和细节的修饰词可以帮助更好地塑造AI的表现。例如，不要说"创建分析仪表板"，而是使用"创建分析仪表板。包含尽可能多的相关功能和交互。超越基础创建功能完整的实现。"

3. **明确请求特定功能**：需要时应该明确请求动画和交互元素。

## 实际应用建议

基于我的使用经验，这里有一些实用的建议：

### 1. 从简单开始，逐步复杂化
不要一次性尝试所有高级技巧。从基本的明确指令开始，然后逐步添加上下文、示例和格式要求。

### 2. 建立提示词模板
为常见任务创建提示词模板，这样可以快速应用最佳实践而不需要每次都重新思考。

### 3. 测试和迭代
不同的模型可能对同一提示词有不同反应。务必在多个模型上测试你的提示词，并根据结果进行调整。

### 4. 记录有效的模式
当你发现某些提示词技巧特别有效时，记录下来并在未来的项目中复用。

## 专业词汇说明

- **提示词工程**：设计和优化AI模型输入提示的技术和艺术
- **上下文窗口**：AI模型在一次交互中能处理的最大文本量
- **Token预算**：上下文窗口中剩余可用token的数量
- **子代理**：专门处理特定任务的辅助AI代理
- **并行工具调用**：同时执行多个工具操作的技术
- **状态跟踪**：在长对话中维护和更新信息状态的能力

## 总结

提示词工程是一个需要不断实践和优化的技能。通过遵循这些最佳实践，你可以显著提高与AI模型交互的效果，无论使用哪种模型。

记住，好的提示词就像是给AI的清晰说明书——越具体、越有上下文、结构越清晰，获得的结果就越好。

希望这些指南能帮助你在下一个AI项目中写出更有效的提示词！